\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[left=0.5in,right=0.5in,top=1in,bottom=1in]{geometry}
\usepackage{amsmath,amssymb,amsfonts,mathtools}
\usepackage{pgfplots,graphicx,calc,changepage}
\pgfplotsset{compat=newest}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage[colorlinks = true, linkcolor = blue]{hyperref}

% Syntax highlighting
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0.40,0.62,0.07}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codeblue}{rgb}{0.09,0.57,0.73}
\definecolor{backcolour}{rgb}{1,1,1}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codeblue},
    basicstyle=\ttfamily\small,
    breaklines=true,                     
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}

\lstset{style=mystyle}

\newcommand{\nats}{\mathbb{N}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\rats}{\mathbb{Q}}
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\comps}{\mathbb{C}}
\newcommand{\pols}{\mathcal{P}}
\newcommand{\cants}{\Delta\!\!\!\!\Delta}
\newcommand{\eps}{\varepsilon}
\newcommand{\st}{\backepsilon}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\dom}[1]{\mathrm{dom}\left(#1\right)}
\newcommand{\for}{\text{ for }}
\newcommand{\dd}[1]{\mathrm{d}#1}
\newcommand{\spn}{\mathrm{sp}}
\newcommand{\nul}{\mathcal{N}}
\newcommand{\col}{\mathrm{col}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\inner}[1]{\left\langle #1 \right\rangle}
\newcommand{\pmat}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\renewcommand{\and}{\text{ and }}

\newsavebox{\qed}
\newenvironment{proof}[2][$\square$]
    {\setlength{\parskip}{0pt}\par\textit{Proof:} #2\setlength{\parskip}{0.25cm}
        \savebox{\qed}{#1}
        \begin{adjustwidth}{\widthof{Proof:}}{}
    }
    {
        \hfill\usebox{\qed}\end{adjustwidth}
    }

\pagestyle{fancy}
\fancyhead{}
\lhead{Caleb Jacobs}
\chead{APPM 5600: Numerical Analysis I}
\rhead{Homework \#8}
\cfoot{}
\setlength{\headheight}{35pt}
\setlength{\parskip}{0.25cm}
\setlength{\parindent}{0pt}

\begin{document}
\section*{Problems}
\begin{enumerate}[label = \arabic*.]
	\item \
		\begin{enumerate}[label = (\roman*)]
			\item Given $ x_0 = -0.2, x_1 = 0, $ and $ x_2 = 0.2 $ construct a second degree polynomial to approximate $ f(x) = e^x $ via Newton's divided differences.
			
			We want to derive a polynomial of the form
			\[
				p(x) = a_0 + a_1 (x - x_0) + a_2 (x - x_0)(x - x_1)
			\]
			where $ a_i = [x_0, \ldots, x_{i-1}] $ are the Newton Divided differences. For this problem, we have
			\begin{align*}
				a_0 &= f[x_0] = e^{x_0} = e^{-0.2}, \\
				a_1 &= f[x_0, x_1] = \frac{e^{x_1} - e^{x_0}}{x_1 - x_0} = \frac{1 - e^{-0.2}}{0.2},\\
				\shortintertext{and} \\
				a_2 &= f[x_0, x_1, x_2] = \frac{f[x_1, x_2] - f[x_0, x_1]}{x_2 - x_0} = \frac{\frac{e^{0.2} - 1}{0.2} - \frac{1 - e^{-0.2}}{0.2}}{0.4}
			\end{align*}
			which makes our polynomial
			\begin{align*}
				p(x) &= e^{-0.2} + \frac{1 - e^{-0.2}}{0.2}(x + 0.2) + \frac{\frac{e^{0.2} - 1}{0.2} - \frac{1 - e^{-0.2}}{0.2}}{0.4} (x + 0.2)(x) \\
				&= 1 + 1.00668 x + 0.501669 x^2.
			\end{align*}
			
			\item Derive an error bound for $ p_2(x) $ when $ x \in [-0.2, 0.2] $.
			
			First, note that the third derivative of $ f $ is maximized over $ [-0.2,0.2] $ when $ x = 0.2 $. Then, we can obtain a bound on our error as
			
			\begin{align*}
				E(t) &\leq \max_{t \in [-0.2, 0.2]} E(t) \\
				&= \max_{t \in [-0.2, 0.2]} \frac{(t + 0.2)(t)(t - 0.2)}{6} e^{0.2} \\
				&= \frac{(-\frac{\sqrt{3}}{15} + 0.2)(-\frac{\sqrt{3}}{15})(-\frac{\sqrt{3}}{15} - 0.2)}{6} e^{0.2} \\
				&= 6.26824 \cdot 10^{-4}.
			\end{align*}
			
			\item Compute the error $ E(0.1) = f(0.1) - p_2(0.1) $. How does this compare with the error bound?
			
			Our error is
			\[
				E(0.1) = \abs{1.10517 - 1.10568} = 5.136621 \cdot 10^{-4}
			\]
			which is within our error bound! So our error bound holds $ x = 0.1 $.
		\end{enumerate}

	\item \
		\begin{enumerate}[label = (\roman*)]
			\item Show there is a unique cubic polynomial $ p(x) $ for which 
			\begin{align*}
				p(x_0) &= f(x_0) & p(x_2) &= f(x_2) \\
				p'(x_1) &= f'(x_1) & p''(x_1) &= f''(x_1)
			\end{align*}
			where $ f(x) $ is a given function and $ x_0 \neq x_2 $.
			
			\item Derive a formula for $ p(x) $.
			
			\item Let $ x_0 = -1, x_1 = 0, $ and $ x_2 = 1 $. Assuming $ f(x) \in C^4[-1,1] $, show that for $ x \in [-1,1] $,
			\[
				f(x) - p(x) = \frac{x^4 - 1}{4!}f^4(\eta_x)
			\]
			for some $ \eta_x \in [-1,1] $.
		\end{enumerate}
	
	\item Suppose we have $ m $ data points $ \{(t_i, y_i)\}_{i = 1}^m $, where the $ t $-values all occur in some interval $ [x_0, x_n] $. We subdivide the interval $ [x_0, x_n] $ into $ n $ subintervals $ \{[x_k, x_{k + 1}]_{k = 0}^{n - 1}\} $ of equal length $ h $ and attempt to choose a spline function $ s(x) $ with nodes at $ \{x_k\}_{k = 0}^n $ in such a way so that
	\[
		\sum_{i = 1}^{m} \abs{y_i - s(t_i)}^2
	\]
	is \emph{minimized}.
		\begin{enumerate}[label = (\roman*)]
			\item \emph{Sheeeeeeeeeeeeesh}
		\end{enumerate}
\end{enumerate}

\section*{Code Used}
\end{document}